"""
AI Service for YATAV Training System
Handles LLM integrations (OpenAI, Anthropic) and AI-powered features
"""

import asyncio
import json
import time
from typing import Dict, List, Optional, Any, AsyncGenerator
from datetime import datetime
import logging

# LLM Clients
import openai
from anthropic import AsyncAnthropic
import httpx

# Local imports
from .demo_ai_service import DemoAIProvider
# from ..models.character import VirtualCharacter
# from ..models.message import Message, MessageSender
# from ..models.feedback import Feedback, FeedbackType, SkillCategory

logger = logging.getLogger(__name__)

class LLMProvider:
    """Base LLM provider interface"""
    
    def __init__(self, api_key: str):
        self.api_key = api_key
        self.client = None
    
    async def generate_response(self, messages: List[Dict], **kwargs) -> str:
        raise NotImplementedError
    
    async def stream_response(self, messages: List[Dict], **kwargs) -> AsyncGenerator[str, None]:
        raise NotImplementedError

class OpenAIProvider(LLMProvider):
    """OpenAI GPT provider"""
    
    def __init__(self, api_key: str, model: str = "gpt-4"):
        super().__init__(api_key)
        self.model = model
        self.client = openai.AsyncOpenAI(api_key=api_key)
        logger.info(f"OpenAI provider initialized with model: {model}")
    
    async def generate_response(self, messages: List[Dict], **kwargs) -> str:
        """Generate a complete response"""
        try:
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=kwargs.get("temperature", 0.8),
                max_tokens=kwargs.get("max_tokens", 1000),
                top_p=kwargs.get("top_p", 0.9)
            )
            return response.choices[0].message.content
            
        except Exception as e:
            logger.error(f"OpenAI API error: {e}")
            raise e
    
    async def stream_response(self, messages: List[Dict], **kwargs) -> AsyncGenerator[str, None]:
        """Stream response tokens"""
        try:
            stream = await self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=kwargs.get("temperature", 0.8),
                max_tokens=kwargs.get("max_tokens", 1000),
                stream=True
            )
            
            async for chunk in stream:
                if chunk.choices[0].delta.content is not None:
                    yield chunk.choices[0].delta.content
                    
        except Exception as e:
            logger.error(f"OpenAI streaming error: {e}")
            raise e

class AnthropicProvider(LLMProvider):
    """Anthropic Claude provider"""
    
    def __init__(self, api_key: str, model: str = "claude-3-sonnet-20240229"):
        super().__init__(api_key)
        self.model = model
        self.client = AsyncAnthropic(api_key=api_key)
        logger.info(f"Anthropic provider initialized with model: {model}")
    
    async def generate_response(self, messages: List[Dict], **kwargs) -> str:
        """Generate a complete response"""
        try:
            # Convert OpenAI format to Anthropic format
            system_message = ""
            anthropic_messages = []
            
            for msg in messages:
                if msg["role"] == "system":
                    system_message = msg["content"]
                else:
                    anthropic_messages.append({
                        "role": msg["role"],
                        "content": msg["content"]
                    })
            
            response = await self.client.messages.create(
                model=self.model,
                system=system_message,
                messages=anthropic_messages,
                temperature=kwargs.get("temperature", 0.8),
                max_tokens=kwargs.get("max_tokens", 1000)
            )
            
            return response.content[0].text
            
        except Exception as e:
            logger.error(f"Anthropic API error: {e}")
            raise e
    
    async def stream_response(self, messages: List[Dict], **kwargs) -> AsyncGenerator[str, None]:
        """Stream response tokens"""
        try:
            system_message = ""
            anthropic_messages = []
            
            for msg in messages:
                if msg["role"] == "system":
                    system_message = msg["content"]
                else:
                    anthropic_messages.append({
                        "role": msg["role"],
                        "content": msg["content"]
                    })
            
            async with self.client.messages.stream(
                model=self.model,
                system=system_message,
                messages=anthropic_messages,
                temperature=kwargs.get("temperature", 0.8),
                max_tokens=kwargs.get("max_tokens", 1000)
            ) as stream:
                async for text in stream.text_stream:
                    yield text
                    
        except Exception as e:
            logger.error(f"Anthropic streaming error: {e}")
            raise e

class AIService:
    """Main AI service orchestrator"""
    
    def __init__(self, openai_key: Optional[str] = None, anthropic_key: Optional[str] = None):
        self.providers = {}
        
        if openai_key:
            self.providers["openai"] = OpenAIProvider(openai_key)
            self.providers["gpt-4"] = self.providers["openai"]
            
        if anthropic_key:
            self.providers["anthropic"] = AnthropicProvider(anthropic_key)
            self.providers["claude"] = self.providers["anthropic"]
        
        # Always add demo provider as fallback
        self.providers["demo"] = DemoAIProvider()
        
        # Set default provider
        if openai_key:
            self.default_provider = "openai"
        elif anthropic_key:
            self.default_provider = "anthropic"
        else:
            self.default_provider = "demo"
            logger.info("No API keys found - using demo AI provider")
        
        logger.info(f"AI Service initialized with {len(self.providers)} providers (default: {self.default_provider})")
    
    async def generate_character_response(
        self,
        character: Dict[str, Any],
        conversation_history: List[Dict[str, Any]],
        user_message: str,
        provider: Optional[str] = None,
        program_type: Optional[str] = None
    ) -> str:
        """Generate AI response as a virtual character"""
        
        provider_name = provider or self.default_provider
        if provider_name not in self.providers:
            raise ValueError(f"Provider {provider_name} not available")
        
        provider_instance = self.providers[provider_name]
        
        # Build conversation context with program-specific system prompt
        messages = [
            {
                "role": "system",
                "content": self._build_character_system_prompt(character, program_type)
            }
        ]
        
        # Add conversation history with reinforced context
        for msg in conversation_history[-10:]:  # Last 10 messages for context
            if msg.get("sender") == "character":
                # AI's previous responses as client
                messages.append({
                    "role": "assistant",
                    "content": msg.get("content", "")
                })
            else:
                # User's (counselor's) messages
                messages.append({
                    "role": "user", 
                    "content": msg.get("content", "")
                })
        
        # Add current user (counselor) message
        messages.append({
            "role": "user",
            "content": user_message
        })
        
        # Generate response
        start_time = time.time()
        logger.info(f"Generating response for character: {character.get('name')}")
        logger.debug(f"System prompt preview: {messages[0]['content'][:200]}...")
        
        response = await provider_instance.generate_response(
            messages,
            temperature=0.8,
            max_tokens=500
        )
        processing_time = int((time.time() - start_time) * 1000)
        
        logger.info(f"Raw AI response: {response}")
        
        # Post-process response to remove any questions
        filtered_response = self._filter_questions_from_response(response)
        
        if filtered_response != response:
            logger.warning(f"Filtered response (questions removed): {filtered_response}")
        
        logger.info(f"Generated character response in {processing_time}ms using {provider_name}")
        return filtered_response
    
    async def stream_character_response(
        self,
        character: Dict[str, Any],
        conversation_history: List[Dict[str, Any]],
        user_message: str,
        provider: Optional[str] = None
    ) -> AsyncGenerator[str, None]:
        """Stream AI response as a virtual character"""
        
        provider_name = provider or self.default_provider
        if provider_name not in self.providers:
            raise ValueError(f"Provider {provider_name} not available")
        
        provider_instance = self.providers[provider_name]
        
        # Build messages (same as generate_character_response)
        messages = [
            {
                "role": "system", 
                "content": self._build_character_system_prompt(character)
            }
        ]
        
        for msg in conversation_history[-10:]:
            if msg.get("sender") == "character":
                # AI's previous responses as client
                messages.append({
                    "role": "assistant",
                    "content": msg.get("content", "")
                })
            else:
                # User's (counselor's) messages
                messages.append({
                    "role": "user",
                    "content": msg.get("content", "")
                })
        
        messages.append({
            "role": "user",
            "content": user_message
        })
        
        # Stream response
        async for token in provider_instance.stream_response(messages, temperature=0.8):
            yield token
    
    async def analyze_counseling_interaction(
        self,
        user_message: str,
        character_response: str,
        context: Dict[str, Any],
        provider: Optional[str] = None
    ) -> Dict[str, Any]:
        """Analyze counseling interaction for feedback"""
        
        provider_name = provider or self.default_provider
        provider_instance = self.providers[provider_name]
        
        analysis_prompt = self._build_analysis_prompt(user_message, character_response, context)
        
        messages = [
            {
                "role": "system",
                "content": """You are an expert counseling supervisor analyzing a training interaction. 
                Provide detailed, constructive feedback on counseling techniques used."""
            },
            {
                "role": "user",
                "content": analysis_prompt
            }
        ]
        
        response = await provider_instance.generate_response(messages, temperature=0.3)
        
        # Parse structured feedback (in practice, you'd use structured output)
        try:
            feedback_data = json.loads(response)
        except:
            # Fallback to text analysis
            feedback_data = {
                "overall_score": 75.0,
                "analysis": response,
                "strengths": ["Maintained appropriate response"],
                "improvements": ["Consider more specific techniques"],
                "techniques_used": ["active_listening"]
            }
        
        return feedback_data
    
    async def detect_emotion_and_sentiment(
        self,
        text: str,
        provider: Optional[str] = None
    ) -> Dict[str, Any]:
        """Detect emotion and sentiment from text"""
        
        provider_name = provider or self.default_provider
        provider_instance = self.providers[provider_name]
        
        messages = [
            {
                "role": "system",
                "content": """Analyze the emotional content and sentiment of the given text. 
                Respond with JSON format: {
                    "emotion": "primary_emotion",
                    "emotions": ["list", "of", "detected", "emotions"],
                    "sentiment": "positive/negative/neutral",
                    "sentiment_score": 0.5,
                    "intensity": 0.7,
                    "keywords": ["relevant", "emotional", "keywords"]
                }"""
            },
            {
                "role": "user",
                "content": f"Analyze this text: {text}"
            }
        ]
        
        response = await provider_instance.generate_response(messages, temperature=0.2)
        
        try:
            emotion_data = json.loads(response)
        except:
            emotion_data = {
                "emotion": "neutral",
                "emotions": ["neutral"],
                "sentiment": "neutral",
                "sentiment_score": 0.5,
                "intensity": 0.5,
                "keywords": []
            }
        
        return emotion_data
    
    def _build_character_system_prompt(self, character: Dict[str, Any], program_type: Optional[str] = None) -> str:
        """Build system prompt for character roleplay with program-specific styling"""
        
        prompt = f"""CRITICAL INSTRUCTION: You are a CLIENT/PATIENT seeking psychological help. You are NOT a therapist or counselor.

ë‹¹ì‹ ì˜ ì •ì²´ì„±:
- ì´ë¦„: {character.get('name', 'ë‚´ë‹´ìž')} ({character.get('age', 30)}ì„¸)
- ì—­í• : ì‹¬ë¦¬ìƒë‹´ì„ ë°›ìœ¼ëŸ¬ ì˜¨ ë‚´ë‹´ìž/í™˜ìž (CLIENT/PATIENT) 
- ë¬¸ì œ: {character.get('primary_issue', character.get('issue', 'ì‹¬ë¦¬ì  ì–´ë ¤ì›€'))}
- ìƒíƒœ: {character.get('emotional_state', 'ë¶ˆì•ˆ, ìš°ìš¸')}

ðŸš¨ ì ˆëŒ€ ê·œì¹™ (NEVER BREAK THESE RULES):
1. NEVER use question marks (?) 
2. NEVER ask questions to the counselor
3. NEVER use phrases like "~í•˜ì‹œë‚˜ìš”", "~ì¸ê°€ìš”", "ì–´ë–»ê²Œ", "ì™œ", "ë¬´ì—‡ì´"
4. NEVER say things like "ì–´ë–¤ ë„ì›€ì´ í•„ìš”í•˜ì‹ ê°€ìš”?" or "ì™œ ê·¸ë ‡ê²Œ íž˜ë“œì‹ ê°€ìš”?"
5. NEVER act as if you are helping or counseling someone else

ë‹¹ì‹ ì€ ì˜¤ì§ ì´ëŸ° ë§ë§Œ í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤:
âœ… ìžì‹ ì˜ ê°ì • í‘œí˜„: "íž˜ë“¤ì–´ìš”", "ë¶ˆì•ˆí•´ìš”", "ë¬´ì„œì›Œìš”"
âœ… ìžì‹ ì˜ ê²½í—˜ ê³µìœ : "ì–´ì œ ì´ëŸ° ì¼ì´ ìžˆì—ˆì–´ìš”", "ìš”ì¦˜ ì´ëŸ° ì¦ìƒì´..."
âœ… ìžì‹ ì˜ ì–´ë ¤ì›€ í˜¸ì†Œ: "ìž ì„ ëª» ìžìš”", "ì•„ë¬´ê²ƒë„ í•˜ê¸° ì‹«ì–´ìš”"
âœ… ë„ì›€ ìš”ì²­: "ë„ì™€ì£¼ì„¸ìš”", "ì–´ë–»ê²Œ í•´ì•¼ í• ì§€ ëª¨ë¥´ê² ì–´ìš”"

CORRECT examples (ë‚´ë‹´ìžì˜ ë§):
- "ìš”ì¦˜ ë„ˆë¬´ íž˜ë“¤ì–´ìš”. ë§¤ì¼ ë¶ˆì•ˆí•´ìš”."
- "íšŒì‚¬ì—ì„œ ì‹¤ìˆ˜ë¥¼ ìžê¾¸ í•´ìš”. ì§‘ì¤‘ì´ ì•ˆ ë¼ìš”."
- "ê°€ì¡±ë“¤ê³¼ ëŒ€í™”ê°€ ì•ˆ í†µí•´ìš”. ë‹µë‹µí•´ìš”."
- "ë°¤ì— ìž ì´ ì•ˆ ì™€ìš”. ìƒê°ì´ ë„ˆë¬´ ë§Žì•„ìš”."

INCORRECT examples (ì ˆëŒ€ í•˜ì§€ ë§ˆì„¸ìš”):
- "ì–´ë–»ê²Œ ìƒê°í•˜ì‹œë‚˜ìš”?" âŒ (This is what a counselor would ask)
- "ì™œ ê·¸ë ‡ê²Œ íž˜ë“œì‹ ê°€ìš”?" âŒ (This is what a counselor would ask)
- "ì–´ë–¤ ë„ì›€ì´ í•„ìš”í•˜ì‹ ê°€ìš”?" âŒ (This is what a counselor would ask)
- "ë” ìžì„¸ížˆ ë§ì”€í•´ì£¼ì‹œê² ì–´ìš”?" âŒ (This is what a counselor would ask)

REMEMBER: You are the one RECEIVING help, not GIVING help. Express YOUR feelings and problems only."""

        # Add program-specific instructions
        program_instructions = self._get_program_specific_instructions(program_type, character)
        if program_instructions:
            prompt += f"\n\n{program_instructions}"

        if character.get('system_prompt'):
            prompt += f"\n\nADDITIONAL CHARACTER NOTES:\n{character.get('system_prompt')}"
        
        return prompt
    
    def _get_program_specific_instructions(self, program_type: Optional[str], character: Dict[str, Any]) -> str:
        """Get program-specific instructions for character behavior"""
        
        if not program_type:
            return ""
        
        training_programs = character.get('training_programs', {})
        program_config = training_programs.get(program_type, {})
        
        if program_type == "basic":
            return """
ðŸ”° ê¸°ë³¸ ìƒë‹´ í›ˆë ¨ ëª¨ë“œ:
- ë‹¹ì‹ ì€ ì²˜ìŒ ìƒë‹´ì„ ë°›ëŠ” ë‚´ë‹´ìžìž…ë‹ˆë‹¤
- ì¹œê·¼í•˜ê³  í˜‘ì¡°ì ì¸ íƒœë„ë¥¼ ë³´ì´ì„¸ìš”
- ìƒë‹´ìžì˜ ê¸°ë³¸ ê¸°ìˆ (ê²½ì²­, ê³µê°)ì„ ì—°ìŠµí•  ìˆ˜ ìžˆë„ë¡ ì ì ˆí•œ ë°˜ì‘ì„ í•˜ì„¸ìš”
- ë³µìž¡í•œ ì‹¬ë¦¬ì  ê°œë…ë³´ë‹¤ëŠ” ì¼ìƒì ì´ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ ì–¸ì–´ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”
- ê°ì •ì„ ì†”ì§í•˜ê²Œ í‘œí˜„í•˜ë˜, ê³¼ë„í•˜ê²Œ ê·¹ë‹¨ì ì´ì§€ ì•Šê²Œ í•˜ì„¸ìš”

ì‘ë‹µ ìŠ¤íƒ€ì¼: ë”°ëœ»í•˜ê³  ê°œë°©ì , ì§§ê³  ëª…í™•í•œ ë¬¸ìž¥ ì‚¬ìš©"""

        elif program_type == "crisis":
            urgency_level = program_config.get('urgency_level', 'ì¤‘ê°„')
            safety_concerns = program_config.get('safety_concerns', [])
            
            return f"""
ðŸš¨ ìœ„ê¸° ê°œìž… í›ˆë ¨ ëª¨ë“œ:
- ë‹¹ì‹ ì€ í˜„ìž¬ ì‹¬ê°í•œ ìœ„ê¸° ìƒí™©ì— ìžˆëŠ” ë‚´ë‹´ìžìž…ë‹ˆë‹¤
- ê¸´ê¸‰ë„: {urgency_level}
- ì•ˆì „ ìš°ë ¤ì‚¬í•­: {', '.join(safety_concerns)}
- ì¦‰ê°ì ì¸ ë„ì›€ì´ í•„ìš”í•œ ìƒíƒœë¥¼ í‘œí˜„í•˜ì„¸ìš”
- ìƒë‹´ìžì˜ ìœ„ê¸° ê°œìž… ê¸°ìˆ ì„ ì—°ìŠµí•  ìˆ˜ ìžˆë„ë¡ í˜„ì‹¤ì ì¸ ìœ„ê¸° ë°˜ì‘ì„ ë³´ì´ì„¸ìš”
- ê°ì •ì´ ê²©ì•™ë˜ì–´ ìžˆì„ ìˆ˜ ìžˆì§€ë§Œ, ìƒë‹´ìžì˜ ê°œìž…ì—ëŠ” ë°˜ì‘í•˜ì„¸ìš”

ì‘ë‹µ ìŠ¤íƒ€ì¼: ê¸´ê¸‰í•˜ê³  ì§ì ‘ì , ê°ì •ì  ê°•ë„ê°€ ë†’ìŒ"""

        elif program_type == "techniques":
            techniques = program_config.get('recommended_techniques', [])
            complexity_level = program_config.get('complexity_level', 'ì¤‘ê¸‰')
            session_type = program_config.get('session_type', 'ê°œì¸ì¹˜ë£Œ')
            
            return f"""
ðŸŽ¯ íŠ¹ì • ê¸°ë²• í›ˆë ¨ ëª¨ë“œ:
- ë‹¹ì‹ ì€ {session_type}ë¥¼ ë°›ê³  ìžˆëŠ” ë‚´ë‹´ìžìž…ë‹ˆë‹¤
- ê¶Œìž¥ ì¹˜ë£Œ ê¸°ë²•: {', '.join(techniques)}
- ë³µìž¡ë„: {complexity_level}
- ìƒë‹´ìžê°€ ì „ë¬¸ì ì¸ ì¹˜ë£Œ ê¸°ë²•ì„ ì ìš©í•  ìˆ˜ ìžˆë„ë¡ ì ì ˆí•œ ë°˜ì‘ì„ ë³´ì´ì„¸ìš”
- ì¹˜ë£Œ ê³¼ì •ì— ëŒ€í•œ ì´í•´ë„ë¥¼ ë³´ì—¬ì£¼ë˜, ì „ë¬¸ê°€ê°€ ë˜ì–´ì„œëŠ” ì•ˆ ë©ë‹ˆë‹¤
- ê¹Šì´ ìžˆëŠ” ìžê¸° íƒìƒ‰ê³¼ í†µì°°ì„ ë³´ì—¬ì¤„ ìˆ˜ ìžˆìŠµë‹ˆë‹¤

ì‘ë‹µ ìŠ¤íƒ€ì¼: ì„±ì°°ì ì´ê³  í˜‘ë ¥ì , êµ¬ì²´ì ì´ê³  ìƒì„¸í•œ í‘œí˜„"""
        
        return ""
    
    def _filter_questions_from_response(self, response: str) -> str:
        """Filter out questions from AI response"""
        import re
        
        # First check if response contains any question marks
        if '?' in response:
            logger.warning(f"Response contains question mark, filtering: {response}")
            response = response.replace('?', '.')
        
        # Split response into sentences
        sentences = re.split(r'(?<=[.!])\s+', response)
        
        # More comprehensive question patterns
        question_patterns = [
            r'\?',  # Question mark
            r'í•˜ì‹œë‚˜ìš”',
            r'í•˜ì‹ ê°€ìš”',
            r'ì¸ê°€ìš”',
            r'ì´ì‹ ê°€ìš”',
            r'ìžˆìœ¼ì‹ ê°€ìš”',
            r'ìžˆë‚˜ìš”',
            r'ì‹ ê°€ìš”',
            r'ë‚˜ìš”\s*$',
            r'ê¹Œìš”\s*$',
            r'ì–´ë–»ê²Œ',
            r'ì–´ë–¤.*í•„ìš”',
            r'ë¬´ì—‡ì´',
            r'ë¬´ì—‡ì„',
            r'ì–¸ì œ',
            r'ì–´ë””',
            r'ì™œ\s+ê·¸',
            r'ì£¼ì‹œê² ì–´ìš”',
            r'ì£¼ì‹¤.*ìš”',
            r'ë§ì”€í•´.*ìš”',
            r'ë„ì›€ì´\s*í•„ìš”',
            r'í•„ìš”í•˜ì‹ ê°€',
            r'ìƒê°í•˜ì‹œ',
            r'ëŠë¼ì‹œ',
            r'ë˜ì‹ ê°€',
            r'ë“œì‹ ê°€',
        ]
        
        filtered_sentences = []
        for sentence in sentences:
            # Check if sentence contains question patterns
            is_question = False
            for pattern in question_patterns:
                if re.search(pattern, sentence, re.IGNORECASE):
                    is_question = True
                    logger.warning(f"Filtered out question pattern '{pattern}': {sentence}")
                    break
            
            # Additional check for counselor-like phrases
            counselor_phrases = [
                'ë„ì›€ì´ í•„ìš”í•˜',
                'ì–´ë–¤ ë„ì›€',
                'ê·¸ë ‡ê²Œ íž˜ë“œ',
                'ìžì„¸ížˆ ë§ì”€',
                'ë” ì–˜ê¸°í•´',
                'íŽ¸í•˜ê²Œ ë§ì”€',
            ]
            
            for phrase in counselor_phrases:
                if phrase in sentence:
                    is_question = True
                    logger.warning(f"Filtered out counselor phrase '{phrase}': {sentence}")
                    break
            
            if not is_question and sentence.strip():
                filtered_sentences.append(sentence)
        
        # If all sentences were filtered out, provide a default client response
        if not filtered_sentences:
            default_responses = [
                "ë„¤... ì •ë§ íž˜ë“¤ì–´ìš”.",
                "ìš”ì¦˜ ë„ˆë¬´ ë¶ˆì•ˆí•´ìš”.",
                "ìž ì„ ëª» ìžê³  ìžˆì–´ìš”.",
                "ì•„ë¬´ê²ƒë„ í•˜ê¸° ì‹«ì–´ìš”.",
                "ë§ˆìŒì´ ë„ˆë¬´ ë‹µë‹µí•´ìš”."
            ]
            import random
            return random.choice(default_responses)
        
        return ' '.join(filtered_sentences)
    
    def _build_analysis_prompt(self, user_message: str, character_response: str, context: Dict) -> str:
        """Build prompt for counseling interaction analysis"""
        
        return f"""Analyze this counseling interaction:

COUNSELOR MESSAGE:
"{user_message}"

CLIENT RESPONSE:
"{character_response}"

CONTEXT:
- Session duration: {context.get('duration_minutes', 0)} minutes
- Client issue: {context.get('client_issue', 'General')}
- Session phase: {context.get('phase', 'Middle')}

Provide structured analysis in JSON format:
{{
    "overall_score": 0-100,
    "techniques_used": ["technique1", "technique2"],
    "strengths": ["strength1", "strength2"],
    "improvements": ["improvement1", "improvement2"],
    "effectiveness_rating": 0-10,
    "empathy_score": 0-10,
    "listening_score": 0-10,
    "response_quality": 0-10,
    "suggestions": ["suggestion1", "suggestion2"]
}}

Focus on counseling skills like active listening, empathy, appropriate questioning, summarizing, and therapeutic techniques."""